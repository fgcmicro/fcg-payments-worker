name: CD

on:
  push:
    branches: [ "main" ]
    paths:
      - 'FCGPagamentos.Worker/**'
      - 'k8s/**'
      - '.github/workflows/cd.yml'
  workflow_dispatch:

env:
  ECR_REPOSITORY: payments-worker
  IMAGE_TAG: latest

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: us-east-1

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build and Push Docker Image
        id: build-push
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          set -e
          
          if [ -z "$ECR_REGISTRY" ]; then
            echo "ERRO: ECR_REGISTRY n√£o est√° definido"
            exit 1
          fi
          
          FULL_IMAGE="$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"
          echo "Building image: $FULL_IMAGE"
          
          docker build -t $FULL_IMAGE -f FCGPagamentos.Worker/Dockerfile FCGPagamentos.Worker/
          
          echo "Pushing image to ECR..."
          docker push $FULL_IMAGE
          
          echo "FULL_IMAGE=$FULL_IMAGE" >> $GITHUB_OUTPUT
          echo "Image $FULL_IMAGE pushed successfully"

      - name: Prepare K8s manifests
        env:
          FULL_IMAGE: ${{ steps.build-push.outputs.FULL_IMAGE }}
          KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          KEY_SECRET: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          KEY_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
          ACC_ID: ${{ secrets.AWS_ACCOUNT_ID }}
          INTERNAL_AUTH_TOKEN: ${{ secrets.INTERNAL_AUTH_TOKEN }}
        run: |
          set -e
          
          echo "Validando vari√°veis obrigat√≥rias..."
          if [ -z "$FULL_IMAGE" ]; then
            echo "ERRO: FULL_IMAGE n√£o est√° definido"
            exit 1
          fi
          if [ -z "$KEY_ID" ] || [ -z "$KEY_SECRET" ] || [ -z "$KEY_TOKEN" ]; then
            echo "ERRO: Credenciais AWS n√£o est√£o definidas"
            exit 1
          fi
          if [ -z "$ACC_ID" ]; then
            echo "ERRO: ACC_ID n√£o est√° definido"
            exit 1
          fi
          
          mkdir -p k8s/payments-worker/processed
          export FULL_IMAGE KEY_ID KEY_SECRET KEY_TOKEN ACC_ID INTERNAL_AUTH_TOKEN
          
          echo "Processando arquivos YAML..."
          if command -v envsubst >/dev/null 2>&1; then
            envsubst < k8s/configmap.yaml > k8s/payments-worker/processed/configmap.yaml
            envsubst < k8s/secret.yaml > k8s/payments-worker/processed/secret.yaml
            envsubst < k8s/deployment.yaml > k8s/payments-worker/processed/deployment.yaml
          else
            sed -e "s|\${FULL_IMAGE}|${FULL_IMAGE}|g" \
                -e "s|\${ACC_ID}|${ACC_ID}|g" \
                k8s/configmap.yaml > k8s/payments-worker/processed/configmap.yaml
            sed -e "s|\${KEY_ID}|${KEY_ID}|g" \
                -e "s|\${KEY_SECRET}|${KEY_SECRET}|g" \
                -e "s|\${KEY_TOKEN}|${KEY_TOKEN}|g" \
                -e "s|\${INTERNAL_AUTH_TOKEN}|${INTERNAL_AUTH_TOKEN}|g" \
                k8s/secret.yaml > k8s/payments-worker/processed/secret.yaml
            sed -e "s|\${FULL_IMAGE}|${FULL_IMAGE}|g" \
                k8s/deployment.yaml > k8s/payments-worker/processed/deployment.yaml
          fi
          
          cp k8s/service.yaml k8s/payments-worker/processed/service.yaml
          cp k8s/hpa.yaml k8s/payments-worker/processed/hpa.yaml
          if [ -f k8s/namespace.yaml ]; then
            cp k8s/namespace.yaml k8s/payments-worker/processed/namespace.yaml
          else
            echo "Aviso: namespace.yaml n√£o encontrado, ser√° criado automaticamente"
          fi
          
          if [ -f k8s/traefik/service.yaml ]; then
            echo "üìã Copiando traefik/service.yaml..."
            cp k8s/traefik/service.yaml k8s/payments-worker/processed/traefik-service.yaml
            if [ ! -f k8s/payments-worker/processed/traefik-service.yaml ]; then
              echo "‚ùå ERRO: Falha ao copiar traefik/service.yaml"
              exit 1
            fi
            echo "‚úÖ traefik-service.yaml copiado com sucesso"
          else
            echo "‚ö†Ô∏è  AVISO: k8s/traefik/service.yaml n√£o encontrado"
          fi
          
          if [ -f k8s/traefik/service-backup.yaml ]; then
            echo "üìã Copiando traefik/service-backup.yaml..."
            cp k8s/traefik/service-backup.yaml k8s/payments-worker/processed/traefik-service-backup.yaml
            echo "‚úÖ traefik-service-backup.yaml copiado com sucesso"
          fi
          
          if grep -r '\${' k8s/payments-worker/processed/*.yaml 2>/dev/null; then
            echo "ERRO: Vari√°veis n√£o substitu√≠das encontradas"
            exit 1
          fi

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig \
            --name ${{ secrets.EKS_CLUSTER_NAME }} \
            --region us-east-1

      - name: Install Helm
        run: |
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          helm version

      - name: Install Traefik
        run: |
          echo "Verificando se o Traefik j√° est√° instalado..."
          
          if kubectl get deployment traefik -n kube-system >/dev/null 2>&1 || \
             kubectl get daemonset traefik -n kube-system >/dev/null 2>&1 || \
             kubectl get deployment traefik -n traefik >/dev/null 2>&1; then
            echo "‚úÖ Traefik j√° est√° instalado no cluster."
            kubectl get pods -n kube-system -l app.kubernetes.io/name=traefik 2>/dev/null || \
            kubectl get pods -n traefik -l app.kubernetes.io/name=traefik 2>/dev/null || true
          else
            echo "üì¶ Traefik n√£o encontrado. Instalando via Helm..."
            
            helm repo add traefik https://traefik.github.io/charts
            helm repo update
            
            echo "Instalando Traefik no namespace kube-system..."
            helm upgrade --install traefik traefik/traefik \
              --namespace kube-system \
              --create-namespace \
              --set service.type=ClusterIP \
              --set ports.web.port=80 \
              --set ports.websecure.port=443 \
              --set additionalArguments[0]=--api.dashboard=false \
              --set additionalArguments[1]=--api.insecure=false \
              --wait \
              --timeout 5m || {
                echo "‚ö†Ô∏è  Erro ao instalar Traefik. Verificando status..."
                kubectl get pods -n kube-system -l app.kubernetes.io/name=traefik || true
                exit 1
              }
            
            echo "‚úÖ Traefik instalado com sucesso!"
            echo "‚è≥ Aguardando pods ficarem prontos..."
            sleep 15
            
            echo "Status do Traefik:"
            kubectl get pods -n kube-system -l app.kubernetes.io/name=traefik || true
          fi

      - name: Verify AWS Load Balancer Controller
        run: |
          echo "üîç Verificando AWS Load Balancer Controller..."
          
          if kubectl get deployment -n kube-system aws-load-balancer-controller >/dev/null 2>&1; then
            echo "‚úÖ AWS Load Balancer Controller encontrado"
            kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller
          else
            echo "‚ö†Ô∏è  AWS Load Balancer Controller N√ÉO encontrado"
            echo ""
            echo "O EKS moderno (1.24+) usa o controlador de servi√ßo integrado."
            echo "Se o Load Balancer n√£o for criado, verifique:"
            echo "1. Permiss√µes IAM do cluster (IRSA ou role do node group)"
            echo "2. Tags das sub-redes (kubernetes.io/role/elb=1 para p√∫blicas)"
            echo "3. Logs do controlador: kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller"
          fi

      - name: Setup Traefik CRDs
        run: |
          echo "Verificando se o Traefik est√° instalado no cluster..."
          
          if kubectl get deployment traefik -n kube-system >/dev/null 2>&1 || \
             kubectl get daemonset traefik -n kube-system >/dev/null 2>&1 || \
             kubectl get deployment traefik -n traefik >/dev/null 2>&1; then
            echo "Traefik encontrado no cluster."
            
            if ! kubectl get crd middlewares.traefik.containo.us >/dev/null 2>&1; then
              echo "CRDs do Traefik n√£o encontrados. Tentando instalar..."
              
              kubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v2.11/docs/content/reference/dynamic-configuration/kubernetes-crd-definition-v1.yml 2>/dev/null || \
              kubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v3.0/docs/content/reference/dynamic-configuration/kubernetes-crd-definition-v1.yml 2>/dev/null || \
              echo "‚ö†Ô∏è  N√£o foi poss√≠vel instalar os CRDs automaticamente."
              
              echo "Aguardando CRDs ficarem dispon√≠veis..."
              sleep 10
            else
              echo "‚úÖ CRDs do Traefik j√° est√£o instalados."
            fi
          else
            echo "‚ö†Ô∏è  Traefik n√£o encontrado no cluster. O middleware ser√° ignorado."
            echo "Para usar o middleware, instale o Traefik primeiro ou use outro Ingress Controller."
          fi

      - name: Deploy to EKS
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          AWS_REGION: us-east-1
        run: |
          set -e
          
          if [ -f k8s/payments-worker/processed/namespace.yaml ]; then
            kubectl apply -f k8s/payments-worker/processed/namespace.yaml
          else
            kubectl create namespace payments-worker --dry-run=client -o yaml | kubectl apply -f -
          fi
          
          if [ -z "$ECR_REGISTRY" ]; then
            ECR_REGISTRY="${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          fi
          
          kubectl delete secret ecr-secret -n payments-worker 2>/dev/null || true
          
          TOKEN=$(aws ecr get-login-password --region $AWS_REGION) || exit 1
          kubectl create secret docker-registry ecr-secret \
            --docker-server="$ECR_REGISTRY" \
            --docker-username=AWS \
            --docker-password="$TOKEN" \
            --namespace=payments-worker || exit 1
          
          CURRENT_IMAGE=$(kubectl get deployment payments-worker-deployment -n payments-worker -o jsonpath='{.spec.template.spec.containers[0].image}' 2>/dev/null || echo "")
          NEW_IMAGE=$(grep "image:" k8s/payments-worker/processed/deployment.yaml | awk '{print $2}' | tr -d '"')
          
          CONFIGMAP_CHANGED=false
          SECRET_CHANGED=false
          
          if kubectl get configmap payments-worker-config -n payments-worker >/dev/null 2>&1; then
            OLD_CONFIGMAP=$(kubectl get configmap payments-worker-config -n payments-worker -o yaml | grep -A 100 "^data:" | sort)
            kubectl apply -f k8s/payments-worker/processed/configmap.yaml >/dev/null 2>&1
            NEW_CONFIGMAP=$(kubectl get configmap payments-worker-config -n payments-worker -o yaml | grep -A 100 "^data:" | sort)
            if [ "$OLD_CONFIGMAP" != "$NEW_CONFIGMAP" ]; then
              CONFIGMAP_CHANGED=true
              echo "üîÑ ConfigMap mudou. Deployment ser√° reiniciado."
            fi
          else
            kubectl apply -f k8s/payments-worker/processed/configmap.yaml >/dev/null 2>&1
            CONFIGMAP_CHANGED=true
            echo "üÜï ConfigMap criado. Deployment ser√° reiniciado."
          fi
          
          if kubectl get secret payments-worker-secret -n payments-worker >/dev/null 2>&1; then
            OLD_SECRET=$(kubectl get secret payments-worker-secret -n payments-worker -o yaml | grep -A 100 "^data:" | sort)
            kubectl apply -f k8s/payments-worker/processed/secret.yaml >/dev/null 2>&1
            NEW_SECRET=$(kubectl get secret payments-worker-secret -n payments-worker -o yaml | grep -A 100 "^data:" | sort)
            if [ "$OLD_SECRET" != "$NEW_SECRET" ]; then
              SECRET_CHANGED=true
              echo "üîÑ Secret mudou. Deployment ser√° reiniciado."
            fi
          else
            kubectl apply -f k8s/payments-worker/processed/secret.yaml >/dev/null 2>&1
            SECRET_CHANGED=true
            echo "üÜï Secret criado. Deployment ser√° reiniciado."
          fi
          
          kubectl apply -f k8s/payments-worker/processed/deployment.yaml
          
          kubectl apply -f k8s/payments-worker/processed/service.yaml
          kubectl apply -f k8s/payments-worker/processed/hpa.yaml
          
          if [ -f k8s/payments-worker/processed/traefik-service.yaml ]; then
            echo "üîç Verificando se o Traefik Service j√° existe..."
            EXISTING_SVC=$(kubectl get svc traefik-loadbalancer -n kube-system 2>/dev/null || echo "")
            
            if [ -n "$EXISTING_SVC" ]; then
              echo "‚úÖ Traefik Service j√° existe. Atualizando sem deletar para preservar o Load Balancer..."
            else
              echo "üì¶ Traefik Service n√£o existe. Criando novo..."
            fi
            
            echo "üîç Verificando se os pods do Traefik est√£o dispon√≠veis..."
            TRAEFIK_PODS=$(kubectl get pods -n kube-system -l app.kubernetes.io/name=traefik -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
            if [ -z "$TRAEFIK_PODS" ]; then
              echo "‚ö†Ô∏è  AVISO: Nenhum pod do Traefik encontrado com label app.kubernetes.io/name=traefik"
              echo "Verificando pods do Traefik:"
              kubectl get pods -n kube-system | grep traefik || echo "Nenhum pod encontrado"
            else
              echo "‚úÖ Pods do Traefik encontrados: $TRAEFIK_PODS"
            fi
            
            echo "‚úÖ Aplicando Traefik Service LoadBalancer..."
            if kubectl apply -f k8s/payments-worker/processed/traefik-service.yaml; then
              echo "‚úÖ Traefik Service aplicado com sucesso!"
              
              echo "üìã Verificando detalhes do service..."
              kubectl get svc traefik-loadbalancer -n kube-system -o yaml | head -30
              
              echo "‚è≥ Aguardando LoadBalancer ser provisionado (pode levar at√© 2 minutos)..."
              for i in {1..12}; do
                sleep 10
                NLB_HOSTNAME=$(kubectl get svc traefik-loadbalancer -n kube-system -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
                if [ -n "$NLB_HOSTNAME" ]; then
                  echo "‚úÖ LoadBalancer criado! Hostname: $NLB_HOSTNAME"
                  break
                else
                  echo "‚è≥ Aguardando... ($i/12)"
                fi
              done
              
              if [ -z "$NLB_HOSTNAME" ]; then
                echo "‚ö†Ô∏è  LoadBalancer ainda n√£o foi provisionado ap√≥s 2 minutos."
                echo "Verificando status do service:"
                kubectl get svc traefik-loadbalancer -n kube-system
                echo ""
                echo "Verificando eventos:"
                kubectl get events -n kube-system --sort-by='.lastTimestamp' | grep traefik-loadbalancer | tail -10 || echo "Nenhum evento encontrado"
              fi
            else
              echo "‚ö†Ô∏è  Erro ao aplicar traefik-service.yaml. Tentando service-backup.yaml..."
              if [ -f k8s/payments-worker/processed/traefik-service-backup.yaml ]; then
                kubectl apply -f k8s/payments-worker/processed/traefik-service-backup.yaml
              else
                echo "‚ùå ERRO: N√£o foi poss√≠vel aplicar o Traefik Service!"
                exit 1
              fi
            fi
          elif [ -f k8s/payments-worker/processed/traefik-service-backup.yaml ]; then
            echo "‚úÖ Aplicando Traefik Service (backup)..."
            kubectl apply -f k8s/payments-worker/processed/traefik-service-backup.yaml
          else
            echo "‚ö†Ô∏è  AVISO: Arquivo traefik-service.yaml n√£o encontrado. O LoadBalancer n√£o ser√° criado."
            echo "Verifique se o arquivo k8s/traefik/service.yaml existe no reposit√≥rio."
          fi
          
          SKIP_ROLLOUT=false
          if [ -n "$CURRENT_IMAGE" ] && [ "$CURRENT_IMAGE" = "$NEW_IMAGE" ] && [ "$CONFIGMAP_CHANGED" = "false" ] && [ "$SECRET_CHANGED" = "false" ]; then
            READY=$(kubectl get deployment payments-worker-deployment -n payments-worker -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
            DESIRED=$(kubectl get deployment payments-worker-deployment -n payments-worker -o jsonpath='{.spec.replicas}' 2>/dev/null || echo "1")
            if [ "$READY" = "$DESIRED" ] && [ "$READY" != "0" ]; then
              echo "‚ÑπÔ∏è  Deployment j√° est√° pronto. Nenhuma mudan√ßa detectada."
              SKIP_ROLLOUT=true
            fi
          fi
          
          if [ "$SKIP_ROLLOUT" = "false" ]; then
            if [ -n "$CURRENT_IMAGE" ] && [ "$CURRENT_IMAGE" != "$NEW_IMAGE" ]; then
              echo "üîÑ Imagem mudou. Reiniciando deployment..."
              kubectl rollout restart deployment/payments-worker-deployment -n payments-worker
            elif [ "$CONFIGMAP_CHANGED" = "true" ] || [ "$SECRET_CHANGED" = "true" ]; then
              echo "üîÑ ConfigMap ou Secret mudou. Reiniciando deployment para aplicar mudan√ßas..."
              kubectl rollout restart deployment/payments-worker-deployment -n payments-worker
            else
              echo "üîÑ Aguardando deployment ficar pronto..."
            fi
          fi
          
          if ! kubectl rollout status deployment/payments-worker-deployment -n payments-worker --timeout=300s; then
            echo "ERRO: Rollout falhou ou timeout"
            echo ""
            echo "=== Status dos pods ==="
            kubectl get pods -n payments-worker -o wide
            echo ""
            echo "=== Descri√ß√£o do deployment ==="
            kubectl describe deployment payments-worker-deployment -n payments-worker
            echo ""
            echo "=== Logs dos pods (√∫ltimos 50 linhas) ==="
            for pod in $(kubectl get pods -n payments-worker -l app=payments-worker -o jsonpath='{.items[*].metadata.name}'); do
              echo "--- Logs do pod: $pod ---"
              kubectl logs $pod -n payments-worker --tail=50 || echo "N√£o foi poss√≠vel obter logs do pod $pod"
              echo ""
              echo "--- Descri√ß√£o do pod: $pod ---"
              kubectl describe pod $pod -n payments-worker | tail -30
              echo ""
            done
            echo ""
            echo "=== Eventos do namespace ==="
            kubectl get events -n payments-worker --sort-by='.lastTimestamp' | tail -20
            exit 1
          fi
          
          echo "Deploy conclu√≠do com sucesso!"

      - name: Verify Deployment
        run: |
          echo "üîç Verificando status do deployment..."
          sleep 10
          
          echo ""
          echo "=== STATUS DO DEPLOYMENT ==="
          kubectl get deployment payments-worker-deployment -n payments-worker
          
          echo ""
          echo "=== STATUS DOS PODS ==="
          kubectl get pods -n payments-worker -l app=payments-worker
          
          echo ""
          echo "=== STATUS DO SERVICE ==="
          kubectl get svc payments-worker-service -n payments-worker
          
          echo ""
          echo "=== STATUS DO HPA ==="
          kubectl get hpa payments-worker-hpa -n payments-worker
